---
title: "clean_data"
author: "Sarah Hvid Andersen"
date: "13/5/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
pacman::p_load(tidyverse, 
               fs, 
               purrr, 
               scales)
```


the data is in the folder students_output. we need to read in the data from each csv file within. 

```{r}

read_data <- function(filename) {
    # getting filenames and subsetting the relevant parts
    files = path_file(path = filename) 
    
    for (file in filename){
    Date = substr(files, 7, 16)
    Version = substr(files, 18, 26)
    }
    
    # creating dataframes, loading data and merging the df's
    df = data_frame(Date, Version)
    df1 = read.csv(filename)
    data = merge(df, df1)
    
    #depending on how many files we want in the same df, we need to make the ID's unique
    data$id <- paste0(data$Version, data$ID)
    
    # cleaning the variables
    data = data %>% mutate(
        id = as.factor(id),
        NumberOfStudents = as.factor(NumberOfStudents)
        )
    
    
    return(data)
}

# testing on one file
test_data = read_data("Students_output/output2021-05-13_171337-0.csv")
    #it works

# now we can apply it to the files we want to collect into one datafram
df_1 <- list.files(path = 'Students_output/', pattern = '.csv', all.files = T, full.names = T) %>% 
    purrr::map_df(read_data)

#correcting ID now that it is one big df
  # there should always be as many Id's as observations in the dataframe
df <- df_1 %>%
  select(-ID) %>% 
  rename(ID = id) %>% 
  mutate(
  ID = as.numeric(ID)) %>% 
  mutate(
  ID = as.factor(ID))
  

# save the full dataset as a csv file
#write_csv(abm_data, 'abm_data.csv')
```


calculating the percentage learned and getting some summary statistics

```{r}

df$Knowledge_percent <-  df$End_knowledge / df$Ticks

sum_stats <- df %>% 
  split(df$NumberOfStudents) %>% 
  map(summary) 

sum_stats



df <- df %>% dplyr::group_by(Version)

df %>% summarise(
  Baseline.attention = mean(Baseline.attention)
)

#Finding the 20% lowest, 60%     
quantile(df$Baseline.attention, c(.20, .60))

df_at <- df %>%
  mutate(Attainment = 
           ifelse(Baseline.attention < 0.7654543,"Low", #Lowest 20%
                  ifelse(Baseline.attention > 0.8618658, "High", "Medium"))) #Over 60%
#For plotting purposes
df_at$NumberOfStudents <- as.character(df_at$NumberOfStudents) %>% as.numeric(df_at$NumberOfStudents)


```


plots

```{r}
#Very nice, looks like we are on to something
ggplot(df, aes(x = NumberOfStudents, y = Knowledge_percent, fill = NumberOfStudents)) +
  geom_bar(stat = "summary", fun.y = mean)+
  geom_errorbar(stat = "summary", fun.data = mean_se)

df %>% ggplot(aes(x = Baseline.attention, y = Version)) + geom_point(aes(color = Version))
df %>% ggplot(aes(x = Baseline.attention)) + geom_histogram() + facet_wrap(.~ Version)

#This looks problematic. Set <95 to random number between 90-95 
ggplot(df, aes(x = Baseline.attention))+
  geom_histogram(bins = 100)

#Boxplot
ggplot(df, aes(x = Baseline.attention ))+ 
  geom_boxplot()


#Plotting knowledge percent as a function of attainment over class size
ggplot(df_at, aes(x = NumberOfStudents, y = Knowledge_percent, color = Attainment))+
  stat_summary()+
  geom_smooth(method = "loess")

#Plotting knowledge percent 
ggplot(df, aes(x = Knowledge_percent)) +
  geom_histogram(bins= 7) 

ggplot(df, aes(x = Knowledge_percent, group = Version) +  
  geom_bar(aes(y = ..count.., fill = factor(..x..)), stat="count") +
    geom_text(aes( label = scales::percent(..prop..),
                   y= ..prop.. ), stat= "count", vjust = -.5) +
    labs(y = "Percent", fill="knowledge_percent") +
    facet_grid(~Version) +
    scale_y_continuous(labels = scales::percent))

?geom_histogram
```





