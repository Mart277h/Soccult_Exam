---
title: "SA_analysis_roll"
author: "Martine Lind Jensen"
date: "17/5/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

pacman::p_load(tidyverse,
               lme4,
               stats, 
               forestmodel, 
               scales)

df <- read_csv("data_csv/roll_eval2.csv")
```

Plots 
```{r}
#scaling data for plotting purposes 
df_scale <- df %>% mutate(Baseline.attention = rescale(Baseline.attention, to = c(-1,1)), 
                          Better_roll = rescale(Better_roll, to = c(-1,1)), 
                          Worse_roll = rescale(Worse_roll, to = c(-1,1)), 
                          End_knowledge = rescale(End_knowledge, to = c(0,1)))
#Plotting 
df_scale %>% ggplot() + 
  geom_smooth(aes(x = Better_roll, y = End_knowledge, color = "Better roll"), method = "lm", se = FALSE,  size = 1.3) +
  geom_smooth(aes(x = Worse_roll, y = End_knowledge, colour="Worse roll"), method = "lm", se = FALSE,  size = 1.3) +
  geom_smooth(aes(x = Baseline.attention, y = End_knowledge, color = "Baseline Attention"), method = "lm", se = FALSE, size = 1.3) + 
  theme_classic() + 
  scale_colour_manual(name="Legend", values=c("cadetblue3", "coral1", "seagreen1")) + 
  theme(legend.position = c(0.8, 0.2)) + 
  ggtitle("Effect of predictors on end knowledge")+ 
  xlab("Values") + 
  ylab("End Knowledge")
```









```{r}
#############  sensitivity function from random dude
sensitivityAnalysis <- function(model,
                                target = NULL,
                                predictors = NULL, #Data Frame
                                predictorsMeans = NULL, #Data Frame
                                samplesN = 101,
                                from = 0.6,
                                to = 1.4,
                                targetPrediction = "ratio", # c("ratio", "absolute")
                                predictionType = "prediction",
                                level = 0.9) {
    
    if (missing(target)) {
        predictors <- model$model[-1]
        target <- model$model[1]
    }
    targetName <- names(target)
    
    target <- target[[1]]
    
    numberPredictors <- ncol(predictors)     
    
    if (missing(predictorsMeans)) {
        initialPredictorsValues <- predictors %>%
            summarise_all(mean)
        
    } else {
        initialPredictorsValues <- predictorsMeans    
    }
    
    initialTargetValue <- mean(predict(model, newdata = initialPredictorsValues))
    
    sensitivityData <- sapply(initialPredictorsValues, function(x) rep(x, samplesN * numberPredictors))
    changeDF <- seq(from, to, length.out = samplesN)
    
    for (i in seq(1, numberPredictors)) {
        sensitivityData[seq((i-1)*samplesN + 1, i * samplesN), i] <- changeDF * initialPredictorsValues[[i]]    
    }
    sensitivityData <- data.frame(sensitivityData)
    
    predictedTarget <- predict(model,
                               newdata = sensitivityData,
                               interval = predictionType,
                               level = level)
    
    predictedTarget <- as.data.frame(predictedTarget)
    
    if (targetPrediction == "ratio")
        predictedTarget <- mutate_all(predictedTarget, function(x) {x / initialTargetValue})
    
    df <- data.frame(normalized.predictor.change = numeric(0),
                     predictor = character(0),
                     normalized.target.change.fit = numeric(0),
                     normalized.target.change.lower= numeric(0),
                     normalized.target.change.upper = numeric(0)) 
    
    for (i in seq(1, numberPredictors)) {
        df <- rbind(df, 
                    data.frame(
                        normalized.predictor.change = changeDF,
                        predictor = names(predictors)[i],
                        normalized.target.change.fit = predictedTarget$fit[seq((i-1)*samplesN + 1, i * samplesN)],
                        normalized.target.change.lower = predictedTarget$lwr[seq((i-1)*samplesN + 1, i * samplesN)],
                        normalized.target.change.upper = predictedTarget$upr[seq((i-1)*samplesN + 1, i * samplesN)]))
    }
    if (targetPrediction == "ratio") {
        gg <- ggplot(df, aes(x = normalized.predictor.change, 
                             group = predictor)) +
            geom_ribbon(aes(ymin = normalized.target.change.lower,
                            ymax = normalized.target.change.upper,
                            fill = predictor), alpha = 0.1) + 
            geom_vline(xintercept = 1,  color = "grey80") + 
            geom_hline(yintercept = 1, color = "grey80") +
            geom_abline(slope = 1, linetype = "dashed", color = "grey80") + 
            geom_abline(slope = -1, intercept = 2, linetype = "dashed", color = "grey80") +
            geom_line(aes(x = normalized.predictor.change,
                          y = normalized.target.change.fit,
                          color = predictor)) +
            ylab(paste("Normalized", targetName, "change")) +
            xlab("Normalized Predictor Change") + 
            theme_few()
    } else {
        gg <- ggplot(df, aes(x = normalized.predictor.change, 
                             group = predictor)) +
            geom_ribbon(aes(ymin = normalized.target.change.lower,
                            ymax = normalized.target.change.upper,
                            fill = predictor), alpha = 0.1) + 
            geom_vline(xintercept = 1,  color = "grey80") + 
            geom_hline(yintercept = initialTargetValue, color = "grey80") +
            geom_line(aes(x = normalized.predictor.change,
                          y = normalized.target.change.fit,
                          color = predictor)) +
            ylab(targetName) + 
            xlab("Normalized Predictor Change") + 
            theme_few()        
    }
    
    variableMeans <- cbind(data.frame(target = initialTargetValue),
                           data.frame(initialPredictorsValues))
    names(variableMeans) <- c(targetName, names(initialPredictorsValues))
    return(list(ggplot = gg,
                predictionData = sensitivityData,
                resultsData = df,
                variableMeans = variableMeans))
}

```


```{r}

cv_function <- function(n) {
  cv = sd(n) / mean(n)
  
  return(cv)
}

cv_function(df$Knowledge_percent)

m1 <- lm(Knowledge_Tick ~ Better_roll + Worse_roll + NumberOfStudents + Baseline.attention , df)
m2 <- lm(Grade_kt ~ Better_roll + Worse_roll + NumberOfStudents + Baseline.attention , df)

summary(m1)
summary(m2)

results <- sensitivityAnalysis(m2, level = 0.9, predictionType = "prediction", targetPrediction = "raw")
plot(results$ggplot)
results$variableMeans
```



plots 

```{r}

#Plotting knowledge percent 
df %>% 
  ggplot(aes(x = Knowledge_percent, y = NumberOfStudents, color = Knowledge_percent)) + 
  geom_jitter() +
  facet_grid(Better_roll ~ Worse_roll) +
  ggtitle("Parameter space for better/worse roll")



# nice comparison plot
df %>% ggplot(aes(x = Knowledge_percent)) +
  geom_histogram(bins = 20) +
  facet_grid(Better_roll ~ Worse_roll) +
  ggtitle("Parameter space for better/worse roll") +
  labs(x = 'Knowledge percent', y = '') +
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())



df %>% ggplot(aes(x = Knowledge_percent, y = Baseline.attention)) +
  geom_point(aes(color = Version)) +
  facet_grid(Better_roll ~ Worse_roll) +
  


```

sensitivity analysis part 2

```{r}
df <- read_csv('data_csv/roll_eval2.csv')


# nice comparison plot
df %>% ggplot(aes(x = Knowledge_Tick)) +
  geom_histogram(bins = 20) +
  facet_grid(Better_roll ~ Worse_roll) +
  ggtitle("Parameter space for better/worse roll") +
  labs(x = 'Knowledge pr tick', y = '') +
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())



df %>% ggplot(aes(x = Grade_kt)) +
  geom_histogram(bins = 20) +
  facet_grid(Better_roll ~ Worse_roll) +
  ggtitle("Parameter space for better/worse roll") +
  labs(x = 'grade', y = '') +
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())


# we go with 1.35 and 0.8 as this distribution approximates the real one the most. 

```

